# hctm

Проблема кейса:
1.небольшое количество данных;
2.алгоритм должен быстро адаптироваться под решение новых задач.
Проведено небольшое исследование.
Найдены варианты:
1.model agnostic meta learning(maml). Данная модель хорошо справляется с задачами при небольшом объеме данных и легко адаптируется под решение новых задач. 
2.нейросеть с рекуррентными слоями. Модель может работать с малыми объемами данных и предсказывать временные ряды.
3.Ансамбль простых моделей с дополнительным классификатором.
Выбран второй вариант, как оптимальный по скорости  разработки и качеству работы. Код будем писать на  Python (tensorfolw, keras, pandas, numpy).
Шаги решения:
1.Из учебной выборки скроем от модели тестовую часть (последние 4 строки);
2. Для обучения будем использовать ряды длиной 20, предсказываю 21точку. В каждой эпохе будем использовать 50 бачей. 
3.Обучать модели будем с различными гиперпараметрами, оценивая их качество   на основе ошибки предсказания по тестовой выборке, как метрику будем использовать MSE.
4. Для предсказаний выберем модель с минимальным MSE.
5.Для предсказания результата обучим лучшую модель на тестовых данных и сделаем прогноз. Сохраним результат прогноза. Модель, обученную на тестовых данных в дальнейшем использовать не будем.
Уникальность:
Данная модель хорошо адаптируется к другим входным данным, поскольку уменьшает среднюю ошибку предсказания независимо от обучающей выборки. При увеличении объема выборки модель сохраняет свою актуальность и улучшает качество предсказания. 
В модели не используется импортное ПО, кроме
бесплатных популярных библиотек.
Особенность:
алгоритм нейросети LSTM способен работать в условиях малого количества обучающих данных.
Возможное улучшение модели:
Было отмечено, что почти все из представленных
рядов можно разнести по нескольким кластерам в зависимости от их мета-характеристик. Полагаем, что обучение отдельных моделей для каждого кластера могло бы увеличить качество обучения и прогнозов.
